# -*- coding: utf-8 -*-
"""Breast_Cancer_prediction.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1zU2_U4HqJHttNtQOmb-1lh1rWFYARIBL
"""

from google.colab import drive
drive.mount('/content/drive')

import pandas as pd
df=pd.read_csv('/content/drive/MyDrive/data.csv')

import numpy as np
import pandas as pd
import sklearn.datasets
from sklearn.model_selection import train_test_split, GridSearchCV
from sklearn.linear_model import LogisticRegression
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import StandardScaler, LabelEncoder

#print 1st 5 rows of dataframe
print(df.head())

print(df.describe())

print(df.isnull().sum())

df.tail()

#no of rows and coulmns in the dataset
df.shape

df.info()

#from sklearn.model_selection import train_test_split
#seprating the features and target
#x=data_frame.drop(columns='label',axis=1)
#y=data_frame['label']
x=df.drop('diagnosis',axis=1)
y=df['diagnosis']

#split into testing and training data
x_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=2)

label_encoder = LabelEncoder()
y_train_encoded = label_encoder.fit_transform(y_train)
y_test_encoded = label_encoder.transform(y_test)

print(x.shape, x_train.shape, x_test.shape)

"""Logistic Regression Model"""

# Create a Logistic Regression Model
LRmodel = LogisticRegression(max_iter=4000)  # Increase max_iter from the default value
LRmodel.fit(x_train, y_train)

# Evaluate the model
x_train_prediction = LRmodel.predict(x_train)

accuracy = accuracy_score(y_train, x_train_prediction)
print(f"Accuracy: {accuracy:.2f}")

# Display classification report
print("Classification Report:")
print(classification_report(y_train, x_train_prediction))

"""
Random Forest Classifier
"""

from sklearn.ensemble import RandomForestClassifier

# Create a Random Forest Classifier
rf_classifier = RandomForestClassifier(n_estimators=100, random_state=42)

# Train the model
rf_classifier.fit(x_train, y_train)

# Make predictions on the test set
y_pred = rf_classifier.predict(x_test)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred)
print(f"Accuracy: {accuracy:.2f}")

# Display classification report
print("Classification Report:")
print(classification_report(y_test, y_pred))

"""SVM"""

from sklearn import svm
from sklearn.metrics import accuracy_score, classification_report
from sklearn.preprocessing import LabelEncoder

# Create an SVM classifier
svm_classifier = svm.SVC(kernel='linear', C=1)

# Train the model
svm_classifier.fit(x_train, y_train_encoded)

# Make predictions on the test set
y_pred_encoded = svm_classifier.predict(x_test)

# Inverse transform numerical predictions back to categorical labels
y_pred_decoded = label_encoder.inverse_transform(y_pred_encoded)

# Evaluate the model
accuracy = accuracy_score(y_test, y_pred_decoded)
print(f"Accuracy: {accuracy:.2f}")

# Display classification report
print("Classification Report:")
print(classification_report(y_test, y_pred_decoded))

import matplotlib.pyplot as plt
import numpy as np

# Replace these variables with the accuracy scores you obtained for each model
accuracy_scores = [0.97, 0.94, 0.95]
models = ['Logistic Regression', 'Random Forest', 'SVM']

# Set a custom color palette
colors = plt.cm.viridis(np.linspace(0, 1, len(models)))

# Plotting the accuracy scores
plt.figure(figsize=(10, 6))
bars = plt.barh(models, accuracy_scores, color=colors)
plt.xlabel('Accuracy Score')
plt.title('Model Comparison - Accuracy Scores')
plt.xlim(0, 1)  # Set x-axis limits to represent accuracy range (0 to 1)

# Displaying the accuracy scores on the bars
for bar, accuracy in zip(bars, accuracy_scores):
    plt.text(bar.get_width(), bar.get_y() + bar.get_height() / 2, f'{accuracy:.4f}', va='center')

# Add legend
plt.legend(['Accuracy Score'])

# Add grid lines
plt.grid(axis='x', linestyle='--', alpha=0.6)

plt.show()

# Example: Making a prediction for a new data point (replace values with your data)
new_data_point = [[1,13.54,14.36,87.46,566.3,0.09779,0.08129,0.06664,0.04781,0.1885,0.05766,0.2699,0.7886,2.058,23.56,0.008462,0.0146,0.02387,0.01315,0.0198,0.0023,15.11,19.26,99.7,711.2,0.144,0.1773,0.239,0.1288,0.2977,0.07259]]
new_prediction = LRmodel.predict(new_data_point)

# Decode the predicted label
predicted_label = label_encoder.inverse_transform(new_prediction)
print("\nPredicted Label for the New Data Point:", predicted_label[0])